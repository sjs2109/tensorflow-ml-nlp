{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F3uGsrMgGkRK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 패키지 불러오기"
      ]
    },
    {
      "metadata": {
        "id": "rVuRbZbUG_Oh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        },
        "outputId": "5faf1d03-0751-4a7a-af83-6a7823860d0c"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/configs.py .\n",
        "!wget https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/data.py\n",
        "!wget https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/main.py  \n",
        "!wget https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/model.py\n",
        "!wget https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/predict.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-24 05:31:19--  https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/configs.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1637 (1.6K) [text/plain]\n",
            "Saving to: ‘configs.py’\n",
            "\n",
            "\rconfigs.py            0%[                    ]       0  --.-KB/s               \rconfigs.py          100%[===================>]   1.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-24 05:31:19 (247 MB/s) - ‘configs.py’ saved [1637/1637]\n",
            "\n",
            "--2019-03-24 05:31:19--  http://./\n",
            "Resolving . (.)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘.’\n",
            "FINISHED --2019-03-24 05:31:19--\n",
            "Total wall clock time: 0.2s\n",
            "Downloaded: 1 files, 1.6K in 0s (247 MB/s)\n",
            "--2019-03-24 05:31:20--  https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10836 (11K) [text/plain]\n",
            "Saving to: ‘data.py’\n",
            "\n",
            "data.py             100%[===================>]  10.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-24 05:31:21 (104 MB/s) - ‘data.py’ saved [10836/10836]\n",
            "\n",
            "--2019-03-24 05:31:23--  https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/main.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3244 (3.2K) [text/plain]\n",
            "Saving to: ‘main.py’\n",
            "\n",
            "main.py             100%[===================>]   3.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-24 05:31:23 (47.8 MB/s) - ‘main.py’ saved [3244/3244]\n",
            "\n",
            "--2019-03-24 05:31:25--  https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5588 (5.5K) [text/plain]\n",
            "Saving to: ‘model.py’\n",
            "\n",
            "model.py            100%[===================>]   5.46K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-24 05:31:25 (73.4 MB/s) - ‘model.py’ saved [5588/5588]\n",
            "\n",
            "--2019-03-24 05:31:28--  https://raw.githubusercontent.com/sjs2109/tensorflow-ml-nlp/master/6.CHATBOT/6.3%20seq2seq/predict.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1582 (1.5K) [text/plain]\n",
            "Saving to: ‘predict.py’\n",
            "\n",
            "predict.py          100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-24 05:31:28 (218 MB/s) - ‘predict.py’ saved [1582/1582]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JNQjHvOXGkRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import model as ml\n",
        "import data\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from configs import DEFINES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJybYqMAGkRY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 사전 만들기"
      ]
    },
    {
      "metadata": {
        "id": "iugrPk_1GkRb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_OUT_PATH = './data_out/'\n",
        "data_out_path = os.path.join(os.getcwd(), DATA_OUT_PATH)\n",
        "os.makedirs(data_out_path, exist_ok=True)\n",
        "char2idx,  idx2char, vocabulary_length = data.load_vocabulary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yWBUkqnGkRk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 데이터 만들기"
      ]
    },
    {
      "metadata": {
        "id": "E8l7TW6CIoCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r data_in ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMiTI-HtGkRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "69d71687-90da-40ef-8a2e-96b759a941a7"
      },
      "cell_type": "code",
      "source": [
        "train_input, train_label, eval_input, eval_label = data.load_data()\n",
        "\n",
        "#TODO3: 실행 안됨, 실행 후 지속적으로 리뷰하겠음\n",
        "\n",
        "# 훈련셋 인코딩 만드는 부분이다.\n",
        "train_input_enc, train_input_enc_length = data.enc_processing(train_input, char2idx)\n",
        "# 훈련셋 디코딩 입력 부분 만드는 부분이다.\n",
        "#train_output_dec, train_output_dec_length = data.dec_input_processing(train_label, char2idx) #TODO1 실행 안되어 확인 필요(AttributeError: module 'data' has no attribute 'dec_output_processing)\n",
        "# 훈련셋 디코딩 출력 부분 만드는 부분이다.\n",
        "#train_target_dec = data.dec_target_processing(train_label, char2idx)\n",
        "\n",
        "# 평가셋 인코딩 만드는 부분이다.\n",
        "#eval_input_enc, eval_input_enc_length = data.enc_processing(eval_input,char2idx)\n",
        "# 평가셋 인코딩 만드는 부분이다.\n",
        "#eval_output_dec, eval_output_dec_length = data.dec_input_processing(eval_label, char2idx)\n",
        "# 평가셋 인코딩 만드는 부분이다.\n",
        "#eval_target_dec = data.dec_target_processing(eval_label, char2idx)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7921/7921 [00:18<00:00, 431.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3617dee6c32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 훈련셋 인코딩 만드는 부분이다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_enc_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# 훈련셋 디코딩 입력 부분 만드는 부분이다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#train_output_dec, train_output_dec_length = data.dec_input_processing(train_label, char2idx) #TODO1 실행 안되어 확인 필요(AttributeError: module 'data' has no attribute 'dec_output_processing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data.py\u001b[0m in \u001b[0;36menc_processing\u001b[0;34m(value, dictionary)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# 경우 이므로 UNK(2)를 넣어 준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0msequence_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '<UNKNWON>'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VqTqfkmcGkRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 체크 포인트 경로 만들기"
      ]
    },
    {
      "metadata": {
        "id": "bbyxhY3fGkRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 현재 경로'./'에 현재 경로 하부에 \n",
        "# 체크 포인트를 저장한 디렉토리를 설정한다.\n",
        "check_point_path = os.path.join(os.getcwd(), DEFINES.check_point_path)\n",
        "# 디렉토리를 만드는 함수이며 두번째 인자 exist_ok가 \n",
        "# True이면 디렉토리가 이미 존재해도 OSError가 \n",
        "# 발생하지 않는다.\n",
        "# exist_ok가 False이면 이미 존재하면 \n",
        "# OSError가 발생한다.\n",
        "os.makedirs(check_point_path, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7vh-wkRGkR0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 에스티 메이터 구성"
      ]
    },
    {
      "metadata": {
        "id": "cIC1A1KAGkR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "467b9e56-ed44-4057-e935-c167a2c6a6b8"
      },
      "cell_type": "code",
      "source": [
        "# 에스티메이터 구성한다.\n",
        "\n",
        "# TODO2: 왜 분류모델이라고 적혀있나요???? s2s이 아닌가요?\n",
        "\n",
        "classifier = tf.estimator.Estimator(\n",
        "        model_fn=ml.model, # 모델 등록한다.\n",
        "        model_dir=DEFINES.check_point_path, # 체크포인트 위치 등록한다.\n",
        "        params={ # 모델 쪽으로 파라메터 전달한다.\n",
        "            'hidden_size': DEFINES.hidden_size, # 가중치 크기 설정한다.\n",
        "            'layer_size': DEFINES.layer_size, # 멀티 레이어 층 개수를 설정한다.\n",
        "            'learning_rate': DEFINES.learning_rate, # 학습율 설정한다. \n",
        "            'vocabulary_length': vocabulary_length, # 딕셔너리 크기를 설정한다.\n",
        "            'embedding_size': DEFINES.embedding_size, # 임베딩 크기를 설정한다.\n",
        "            'embedding': DEFINES.embedding, # 임베딩 사용 유무를 설정한다.\n",
        "            'multilayer': DEFINES.multilayer, # 멀티 레이어 사용 유무를 설정한다.\n",
        "        })"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './data_out/check_point', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8c971b80b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1h5pV6vGkR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 학습 실행"
      ]
    },
    {
      "metadata": {
        "id": "y-v9sxEaGkR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "c35ec89d-4394-42e7-e206-eb92b41816f5"
      },
      "cell_type": "code",
      "source": [
        "# 학습 실행\n",
        "classifier.train(input_fn=lambda:data.train_input_fn(\n",
        "    train_input_enc, train_output_dec, train_target_dec,  DEFINES.batch_size), steps=DEFINES.train_steps)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-466c79b13a87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier.train(input_fn=lambda:data.train_input_fn(\n\u001b[0;32m----> 2\u001b[0;31m     train_input_enc, train_output_dec, train_target_dec,  DEFINES.batch_size), steps=DEFINES.train_steps)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1149\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m   1150\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[0;32m-> 1151\u001b[0;31m               input_fn, model_fn_lib.ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m   1152\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m       estimator_spec = self._call_model_fn(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[0;32m--> 992\u001b[0;31m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1077\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-466c79b13a87>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier.train(input_fn=lambda:data.train_input_fn(\n\u001b[0;32m----> 2\u001b[0;31m     train_input_enc, train_output_dec, train_target_dec,  DEFINES.batch_size), steps=DEFINES.train_steps)\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_input_enc' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H7NUhpocGkSE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 평가 하기"
      ]
    },
    {
      "metadata": {
        "id": "dxTmS_F4GkSG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eval_result = classifier.evaluate(input_fn=lambda:data.eval_input_fn(\n",
        "    eval_input_enc, eval_output_dec, eval_target_dec,  DEFINES.batch_size))\n",
        "print('\\nEVAL set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxtMDWfnGkSM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 테스트 하기"
      ]
    },
    {
      "metadata": {
        "id": "KvRGVJLNGkSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 테스트용 데이터 만드는 부분이다.\n",
        "# 인코딩 부분 만든다.\n",
        "predic_input_enc, predic_input_enc_length = data.enc_processing([\"가끔 궁금해\"], char2idx)\n",
        "# 학습 과정이 아니므로 디코딩 입력은 \n",
        "# 존재하지 않는다.(구조를 맞추기 위해 넣는다.)\n",
        "predic_output_dec, predic_output_decLength = data.dec_input_processing([\"\"], char2idx)       \n",
        "# 학습 과정이 아니므로 디코딩 출력 부분도 \n",
        "# 존재하지 않는다.(구조를 맞추기 위해 넣는다.)\n",
        "predic_target_dec = data.dec_target_processing([\"\"], char2idx)      \n",
        "\n",
        "# 예측을 하는 부분이다.\n",
        "predictions = classifier.predict(\n",
        "    input_fn=lambda:data.eval_input_fn(predic_input_enc, predic_output_dec, predic_target_dec, DEFINES.batch_size))\n",
        "\n",
        "# 예측한 값을 인지 할 수 있도록 \n",
        "# 텍스트로 변경하는 부분이다.\n",
        "data.pred2string(predictions, idx2char)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}